# -*- coding: utf-8 -*-
"""Image_classification1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vpmSfOcqYvg5USPJtj01PIddFILb7uut
"""

#!pip list > requirment.txt

#!unzip "/content/drive/MyDrive/2021_iraosuhas/seg_train.zip" -d "/content/drive/MyDrive/2021_iraosuhas"
#!unzip "/content/drive/MyDrive/2021_iraosuhas/seg_test.zip" -d "/content/drive/MyDrive/2021_iraosuhas"
#!unzip "/content/drive/MyDrive/2021_iraosuhas/seg_pred.zip" -d "/content/drive/MyDrive/2021_iraosuhas"

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm

import os
os.chdir('/content/drive/MyDrive/2021_iraosuhas')
import glob
import cv2
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ReduceLROnPlateau
from tensorflow.keras import Model, Sequential
from tensorflow.keras import layers

import tensorflow as tf
from model_files.utils import get_the_classes
from model_files.model import create_model
np.random.seed(123)

'''from google.colab import drive
drive.mount('/content/drive')'''

##Get the trainning data
train_path = '/content/drive/MyDrive/2021_iraosuhas/seg_train'
class_dict, classes = get_the_classes(train_path)
print(classes) 
print(class_dict)

##Building the train data frame:
#Get the list of the files and classes
image_file_name = glob.glob('**/**')
class_for_file = [ file.split('/')[0] for file in image_file_name]

#create the data frame
image_data_train =  pd.DataFrame({'filename':image_file_name, 'classes': class_for_file})
image_data_train = shuffle(image_data_train)
image_data_train = image_data_train.reset_index(drop=True)

image_data_train['classes'] = image_data_train['classes'].map(class_dict)

##Get the trainning data
print('Train sample: ', len(image_data_train['classes']), dict(image_data_train['classes'].value_counts()))

##------------------------------------------------------------------------

##Get the test data
test_path = '/content/drive/MyDrive/2021_iraosuhas/seg_test'
test_class_dict, test_classes = get_the_classes(test_path)

##Building the test data frame:
#Get the list of the files and classes
os.chdir(test_path)
image_file_name = glob.glob('**/**')
class_for_file = [ file.split('/')[0] for file in image_file_name]

#create the data frame
image_data_test =  pd.DataFrame({'filename':image_file_name, 'classes': class_for_file})
image_data_test = shuffle(image_data_test)
image_data_test = image_data_test.reset_index(drop=True)

image_data_test['classes'] = image_data_test['classes'].map(class_dict)
print('Test sample: ', len(image_data_test['classes']), dict(image_data_test['classes'].value_counts()))

image_data_train.head(6)

print(image_data_train.shape)

## Spliting the test to have the validation set as the training data set is already having less images.
data_test, data_val  = train_test_split(image_data_test, test_size=0.5, random_state=42, stratify=image_data_test['classes'])

print('Spliting into test and val, 50%')
print('Test sample: ', len(data_test['classes']), dict(data_test['classes'].value_counts()))
print('Val  sample: ', len(data_val['classes']), dict(data_val['classes'].value_counts()))

data_test.reset_index(drop=True, inplace=True)
data_val.reset_index(drop=True, inplace=True)

##Get the prediction data, unlabeled
pred_path = '/content/drive/MyDrive/2021_iraosuhas/seg_pred'
filename = glob.glob('*')
image_data_pred = pd.DataFrame({'filename':filename})
print(len(image_data_pred))
#print('Pred sample: ', len(image_data_pred['classes']), dict(image_data_pred['classes'].value_counts()))

image_data_train['filename'][0]

# Read the image files and get the images arrays
IMAGE_SIZE = (150,150)
images = []
for im_file in tqdm(image_data_train['filename']):
  #print(im_file)
  image = cv2.imread(im_file)
  image = cv2.resize(image,IMAGE_SIZE)
  images.append(image)

images_train = np.array(images)
labels_train = image_data_train['classes'].value
print(images.shape)
print(input_labels.shape)

##Store the images file:
np.save('/content/drive/MyDrive/2021_iraosuhas/model_files/images_train.npy', images_train)

# Read the image files and get the images arrays
IMAGE_SIZE = (150,150)
images = []
for im_file in tqdm(data_val['filename']):
  #print(im_file)
  image = cv2.imread(im_file)
  image = cv2.resize(image,IMAGE_SIZE)
  images.append(image)

images_val = np.array(images)
labels_val = data_val['classes'].values
print(images_val.shape)
print(labels_val.shape)

##Store the images file:
np.save('/content/drive/MyDrive/2021_iraosuhas/model_files/images_val.npy', images_val)

"""os.chdir(train_path)
##Plot the images
f,ax = plt.subplots(3,3) 
f.subplots_adjust(0,0,3,3)
for i in range(0,3,1):
    for j in range(0,3,1):
        rnd_number = np.random.randint(0,len(images))
        ax[i,j].imshow(images[rnd_number])
        ax[i,j].set_title([key for key, val in class_dict.items() if val == class_dict[rnd_number]][0])
        ax[i,j].axis('off')"""

plt.imshow(images[1]), plt.imshow(images[2])

##Build the random model with any set of layers

IMAGE_SIZE = (150,150)
model = create_model(IMAGE_SIZE, classes)
model.summary()

import datetime
init_time = datetime.datetime.now()

BATCH_SIZE = 30
EPOCHS = 5
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 1, verbose=1, factor=0.3, min_lr=0.000001)

trained = model.fit(
                    train_images, train_labels,
                    validation_data = (val_images, val_labels),
                    batch_size = BATCH_SIZE, 
                    epochs=EPOCHS,
                    callbacks=[learning_rate_reduction],
                  )

requared_time = datetime.datetime.now() - init_time
print(f'\nRequired time:  {str(requared_time)}\n')

plt.plot(trained.history['accuracy'])
plt.plot(trained.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.plot(trained.history['loss'])
plt.plot(trained.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

val_loss, val_acc = model.evaluate(val_images, val_labels, verbose=0)
print('\naccuracy:', val_acc, '  loss: ',val_loss)

predict = np.argmax(model.predict(val_images), axis=1)
predict

from sklearn.metrics import confusion_matrix, classification_report

print(classification_report(val_labels, predict))
print(confusion_matrix(val_labels, predict))

IMAGE_SIZE

###pretrained model

model = pre_model()
model.summary()

init_time = datetime.datetime.now()
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 1, verbose=1, factor=0.3, min_lr=0.000001)

BATCH_SIZE = 30
EPOCHS = 10
trained = model.fit(
                    train_images, train_labels,
                    validation_data = (val_images, val_labels),
                    batch_size = BATCH_SIZE, 
                    epochs=EPOCHS,
                    callbacks=[learning_rate_reduction],
    )

requared_time = datetime.datetime.now() - init_time
print(f'\nRequired time:  {str(requared_time)}\n')

plt.plot(trained.history['accuracy'])
plt.plot(trained.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.plot(trained.history['loss'])
plt.plot(trained.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)
print('\naccuracy:', test_acc, '  loss: ',test_loss)

predict = np.argmax(model.predict(test_images), axis=1)
predict

from sklearn.metrics import confusion_matrix, classification_report

print(classification_report(test_labels, predict))
print(confusion_matrix(test_labels, predict))

# save model and architecture to single file
os.chdir('/content/drive/MyDrive/2021_iraosuhas/saved_model')
model.save("model_vgg.h5")
print("Saved model to disk")

from keras.models import load_model
#model saved path.
os.chdir('/content/drive/MyDrive/2021_iraosuhas/saved_model')
# load model
model = load_model('model.h5')
# summarize model.
model.summary()

file = image_data_train['filename'][0]
image = cv2.imread('/content/drive/MyDrive/2021_iraosuhas/seg_pred/10004.jpg')

image

BATCH_SIZE = 22
a = image_data_train[ : image_data_train.shape[0] // BATCH_SIZE * BATCH_SIZE]

a.shape

image_data_train.shape

image_data_train.shape[0] // 2 * 2

image_data_train.shape[0] - 22

image_data_train.shape

